# AttentionGAN

## Contribution

- We propose a new Attention-Guided Generative Adversarial Network (AttentionGAN) for unpaired image-to-image translation. This framework stabilizes the GANs training and thus improves the quality of generated images through jointly approximating attention and content masks with several losses and optimization methods.
- We design two novel attention-guided generation schemes for the proposed framework, to better perceive and generate the most discriminative foreground parts and simultaneously preserve well the unfocused objects and background. Moreover, the proposed attention-guided generator and discriminator can be flexibly applied in other GANs to improve multi-domain image-to-image translation tasks, which we believe would also be beneficial to other related research.



## Network Structure

## Scheme I

<img src="C:/Users/Kevin/Desktop/research-papers-categorized/assets/images/cyclegan-scheme1-network.PNG" alt="cyclegan-scheme1-network" style="zoom:75%;" />
$$
G(x)=C_y*A_y+x*(1-A_y)\\
F(y)=C_x*A_x+x*(1-A_x)
$$
Limitations:

- The attention and the content mask are generated by the same network, which could degrade the quality of the generated images
- Scheme I only produces one attention mask to simultaneously change the foreground and preserve the background of the input images
- Scheme I only produces one content mask to select useful content for generating the foreground content, which means the model does not have enough ability to deal with complex tasks such as horse to zebra translation



## Scheme II

<img src="C:/Users/Kevin/Desktop/research-papers-categorized/assets/images/cyclegan-scheme2-network.PNG" alt="cyclegan-scheme2-network" style="zoom:100%;" />

Three generators:

- Parameter-sharing encoder $G_E$: extracts both low-level and high-level deep feature representations. 
- Content mask generator $G_C:$ targets to produce multiple intermediate content masks.
- Attention mask generator $G_A$: tries to generate multiple attention masks.

$$
G(x)=\sum_{f=1}^{n-1}(C_y^f*A_y^f)+x*A_y^b
$$



## Attention-Guided Cycle

Only for Scheme I.



## Attention-Guided Discriminator (Scheme I Only)

$$
\mathcal{L}_{AGAN}(G,D_{YA})=E_{y\sim p_{data}(y)}[log(D_{YA}([A_y,y]))]+E_{x\sim p_{data}(x)}[log(1-D_{YA}([A_y,G(x)]))]
$$



## Optimization Objective

Omitted.